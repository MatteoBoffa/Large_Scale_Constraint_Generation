{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb4dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load root folder of the Git project\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "repo_root = Path(\n",
    "    subprocess.check_output(\n",
    "        [\"git\", \"rev-parse\", \"--show-toplevel\"],\n",
    "        text=True\n",
    "    ).strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02caaeef-5dab-4a4c-a8b9-06beb5c3cc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/det_user/mboffa/envs/rule_constrainer/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['gem_id', 'gem_parent_id', 'concept_set_id', 'concepts', 'target', 'references'],\n",
       "        num_rows: 67389\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['gem_id', 'gem_parent_id', 'concept_set_id', 'concepts', 'target', 'references'],\n",
       "        num_rows: 993\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['gem_id', 'gem_parent_id', 'concept_set_id', 'concepts', 'target', 'references'],\n",
       "        num_rows: 1497\n",
       "    })\n",
       "    challenge_train_sample: Dataset({\n",
       "        features: ['gem_id', 'gem_parent_id', 'concept_set_id', 'concepts', 'target', 'references'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    challenge_validation_sample: Dataset({\n",
       "        features: ['gem_id', 'gem_parent_id', 'concept_set_id', 'concepts', 'target', 'references'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    challenge_test_scramble: Dataset({\n",
       "        features: ['gem_id', 'gem_parent_id', 'concept_set_id', 'concepts', 'target', 'references'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "DATASET = \"GEM/common_gen\"\n",
    "CACHE_DIR = repo_root / \"offline_datasets/original/CommonGen/\"\n",
    "data = datasets.load_dataset(DATASET, cache_dir=CACHE_DIR)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221fd03-f761-4341-8abc-b72f5bda9a94",
   "metadata": {},
   "source": [
    "## Convert dataset to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860b4af5-67a0-422d-8807-b3635baac529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gem_id</th>\n",
       "      <th>gem_parent_id</th>\n",
       "      <th>concept_set_id</th>\n",
       "      <th>concepts</th>\n",
       "      <th>target</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_gen-challenge_train_sample-0</td>\n",
       "      <td>common_gen-train-56135</td>\n",
       "      <td>25441</td>\n",
       "      <td>[bathroom, include, shower, toilet]</td>\n",
       "      <td>The interior of a modern bathroom including to...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_gen-challenge_train_sample-1</td>\n",
       "      <td>common_gen-train-57322</td>\n",
       "      <td>25968</td>\n",
       "      <td>[image, number, step, title]</td>\n",
       "      <td>image titled change the number of recent items...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                gem_id           gem_parent_id  \\\n",
       "0  common_gen-challenge_train_sample-0  common_gen-train-56135   \n",
       "1  common_gen-challenge_train_sample-1  common_gen-train-57322   \n",
       "\n",
       "   concept_set_id                             concepts  \\\n",
       "0           25441  [bathroom, include, shower, toilet]   \n",
       "1           25968         [image, number, step, title]   \n",
       "\n",
       "                                              target references  \n",
       "0  The interior of a modern bathroom including to...         []  \n",
       "1  image titled change the number of recent items...         []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.DataFrame(data[\"train\"])\n",
    "df_valid = pd.DataFrame(data[\"validation\"])\n",
    "df_test = pd.concat([pd.DataFrame(data[\"challenge_train_sample\"]),\n",
    "                     pd.DataFrame(data[\"challenge_validation_sample\"])])\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6391a3-f7ba-4088-8b13-988d7231b801",
   "metadata": {},
   "source": [
    "## Now get all the single concepts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26f69db-e781-43c5-98f4-ffeb5d2b8fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 4,792 unique concepts.\n"
     ]
    }
   ],
   "source": [
    "training_concepts = df_train[\"concepts\"].explode(\"concepts\").to_list()\n",
    "validation_concepts = df_valid[\"concepts\"].explode(\"concepts\").to_list()\n",
    "test_concepts = df_test[\"concepts\"].explode(\"concepts\").to_list()\n",
    "full_concepts = set(training_concepts + validation_concepts + test_concepts)\n",
    "print(f\"The dataset contains {len(full_concepts):,} unique concepts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426b340-e0d2-4a98-9031-747f051bc57d",
   "metadata": {},
   "source": [
    "## Now, let's focus on the test samples\n",
    "- We want to make sure to randomly create samples respecting the rules and other not respecting them\n",
    "- Each sample here must contains hundreds, if not thousands, of rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f92caa0-1491-47de-b403-0f5456addf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 5/5 [00:00<00:00, 28263.50it/s]\n",
      "Building nested pools...: 100%|██████████| 1000/1000 [00:02<00:00, 383.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1,000 examples for the scenario with 5 rules\n",
      "Generated 1,000 examples for the scenario with 10 rules\n",
      "Generated 1,000 examples for the scenario with 100 rules\n",
      "Generated 1,000 examples for the scenario with 500 rules\n",
      "Generated 1,000 examples for the scenario with 1000 rules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "SEED = 29\n",
    "random.seed(SEED)\n",
    "\n",
    "n_rules = [5, 10, 100, 500, 1_000]\n",
    "p_contains_world = 0.5\n",
    "output_dict = {}\n",
    "\n",
    "max_rules = max(n_rules)\n",
    "\n",
    "# We will create different versions of the datasets (with different number of rules)\n",
    "for n_rule in tqdm(n_rules, total=len(n_rules), desc=\"Processing...\"):\n",
    "    output_dict[n_rule] = []\n",
    "\n",
    "# IMPORTANT: build each test row once, then slice for each n_rule\n",
    "for test_row_id in tqdm(range(df_test.shape[0]), desc=\"Building nested pools...\"):\n",
    "    test_row = df_test.iloc[test_row_id]\n",
    "    test_concepts = list(test_row[\"concepts\"])\n",
    "    test_sentence = test_row[\"target\"]\n",
    "\n",
    "    # Decide if this row is a \"match\" row (same decision reused for all pool sizes)\n",
    "    contains_words = (random.random() < p_contains_world)\n",
    "\n",
    "    if contains_words:\n",
    "        # choose how many concepts are actually matched (fixed for this row across pool sizes)\n",
    "        # (kept similar to your original; adjust if you want to allow all concepts)\n",
    "        n_matching_concepts = random.randint(1, len(test_concepts) - 1)\n",
    "        matching_concepts = test_concepts[:n_matching_concepts]\n",
    "    else:\n",
    "        matching_concepts = []\n",
    "\n",
    "    # Build ONE long ordered list of distractors for this row (so pools are nested)\n",
    "    samplable_concepts = list(full_concepts - set(test_concepts))\n",
    "    # sample enough distractors to support the largest pool size\n",
    "    distractors = random.sample(samplable_concepts, k=max_rules)\n",
    "\n",
    "    for n_rule in n_rules:\n",
    "        # Number of distractors needed at this pool size\n",
    "        n_distractors_needed = n_rule - len(matching_concepts)\n",
    "        if n_distractors_needed < 0:\n",
    "            # If matching_concepts exceeds n_rule, truncate matching_concepts for this pool size\n",
    "            # (rare unless n_rule < len(matching_concepts))\n",
    "            used_matching = matching_concepts[:n_rule]\n",
    "            used_distractors = []\n",
    "        else:\n",
    "            used_matching = matching_concepts\n",
    "            used_distractors = distractors[:n_distractors_needed]\n",
    "\n",
    "        sampled_concepts = used_matching + used_distractors\n",
    "\n",
    "        # Shuffle presentation order (seeded random makes this reproducible)\n",
    "        shuffled_concepts = sampled_concepts[:]\n",
    "        random.shuffle(shuffled_concepts)\n",
    "\n",
    "        sample = {\n",
    "            \"sentence\": test_sentence,\n",
    "            \"concepts\": shuffled_concepts,\n",
    "            \"contains_concept\": contains_words,\n",
    "            \"concepts_contained\": used_matching,\n",
    "        }\n",
    "        output_dict[n_rule].append(sample)\n",
    "\n",
    "for n_rule in n_rules:\n",
    "    print(f\"Generated {len(output_dict[n_rule]):,} examples for the scenario with {n_rule} rules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb45800-42ba-485c-9ff4-723149553f96",
   "metadata": {},
   "source": [
    "### Now, an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f9eaf3-b4f5-4aab-821d-60e3884fa29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains rule: False\n",
      "\n",
      "Task: I need to check if a sentence contains one of the following set of words. Just answer True or False.\n",
      "Sentence: how did horses and traders change the way of life of ethnicity in fiction\n",
      "\n",
      "Rules (5): poetry - leader - ornate - glacier - cricket\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_ID = 36\n",
    "SCENARIO = 5\n",
    "print(\"Contains rule: \" + str(output_dict[SCENARIO][EXAMPLE_ID][\"contains_concept\"]))\n",
    "if len(output_dict[SCENARIO][EXAMPLE_ID][\"concepts_contained\"])!=0:\n",
    "    print(f\"\\tContains the concepts: {output_dict[SCENARIO][EXAMPLE_ID]['concepts_contained']}\")\n",
    "print()\n",
    "print(\"Task: I need to check if a sentence contains one of the following set of words. Just answer True or False.\")\n",
    "print(\"Sentence: \" + output_dict[SCENARIO][EXAMPLE_ID][\"sentence\"])\n",
    "concepts = output_dict[SCENARIO][EXAMPLE_ID][\"concepts\"]\n",
    "print(f\"\\nRules ({len(concepts)}): \" + \" - \".join(concepts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc8d787-371f-4f60-9c96-d2544806501b",
   "metadata": {},
   "source": [
    "## Save output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7d0c12d-edde-4f5e-93ae-e8835e8ae07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "OUTPUT_DIR = repo_root / \"offline_datasets/processed_dataset/CommonGen/test_many_rules/\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "for scenario, item in output_dict.items():\n",
    "    full_path = OUTPUT_DIR / f\"exact_matching_{scenario}.json\"\n",
    "    with open(full_path, \"w+\") as f:\n",
    "        json.dump(item, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
